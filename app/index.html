<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Detection with TensorFlow.js</title>
    <script
            src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js"
            crossorigin="anonymous"
            type="module"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script> <!-- Include TensorFlow.js -->
</head>
<body>
<h1>Face Detection Example</h1>
<img id="image" src="example.jpeg"> <!-- Hide original image -->
<h2>Detected Face</h2>
<canvas id="faceCanvas" style="border: 1px solid black;display: none"></canvas>
<script type="module">
    import {FilesetResolver, FaceDetector} from 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js';

    async function runFaceDetection() {
        const vision = await FilesetResolver.forVisionTasks(
            "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
        );

        const faceDetector = await FaceDetector.createFromOptions(
            vision,
            {
                baseOptions: {
                    modelAssetPath: "shared/models/blaze_face_short_range.tflite"
                },
                runningMode: 'IMAGE'
            }
        );

        const img = document.getElementById('image');
        img.crossOrigin = 'anonymous'; // Allow cross-origin requests if needed

        // Wait for the image to be loaded
        await new Promise((resolve, reject) => {
            img.onload = resolve;
            img.onerror = reject;
        });

        console.log('Image loaded');
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d');
        canvas.width = img.width;
        canvas.height = img.height;
        ctx.drawImage(img, 0, 0, img.width, img.height);

        const imageData = ctx.getImageData(0, 0, img.width, img.height);
        console.log('Image data:', imageData);

        try {
            const detections = await faceDetector.detect(imageData);
            console.log('Detections:', detections);

            if (detections && detections.detections.length > 0) {
                // Assuming the first detection is the face we want
                const face = detections.detections[0];
                const {originX, originY, width, height} = face.boundingBox;
                console.log(originX, originY, width, height)

                // Create a new canvas for the face
                const faceCanvas = document.getElementById('faceCanvas');
                const faceCtx = faceCanvas.getContext('2d');
                faceCanvas.width = width;
                faceCanvas.height = height;

                // Draw the face on the new canvas
                faceCtx.drawImage(
                    img,
                    originX, originY, width, height, // Source rectangle
                    0, 0, width, height // Destination rectangle
                );

                // Optionally create a new image element from the canvas
                const faceImage = new Image();
                faceImage.src = faceCanvas.toDataURL();
                faceImage.id = 'face'
                document.body.appendChild(faceImage);

                // Load a TensorFlow.js model
                const model = await tf.loadLayersModel('shared/models/sunglasses/model.json');

                const tensor = tf.browser.fromPixels(document.getElementById('face'));

                const resizedTensor = tf.image.resizeBilinear(tensor, [224, 224]); // Use your model's input size
                const normalizedTensor = resizedTensor.toFloat().div(tf.scalar(255)); // Normalize if needed

                // Expand dimensions to match model's input shape (typically [batchSize, height, width, channels])
                const batchedTensor = normalizedTensor.expandDims(0);

                // Run inference
                const predictions = await model.predict(batchedTensor);
// Convert predictions to an array to see the values
                const predictionsArray = predictions.arraySync();

// Log the predictions
                console.log(predictionsArray);

// Dispose of tensors to avoid memory leaks
                tensor.dispose();
                resizedTensor.dispose();
                normalizedTensor.dispose();
                batchedTensor.dispose();
                predictions.dispose();
                console.log(999, predictions)

            } else {
                console.log('No faces detected');
            }
        } catch (error) {
            console.error('Error during face detection:', error);
        }
    }

    runFaceDetection();
</script>
</body>
</html>
